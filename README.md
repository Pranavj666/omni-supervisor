# Omni-Supervisor - AI Observability Dashboard

Real-time monitoring dashboard for AI chatbot conversations with automatic detection of hallucinations and user frustration.

## Features

- **Real-time Chat Monitoring**: View all active conversations in a clean, organized interface
- **Sentiment Analysis**: Automatically detect user frustration using negative keyword detection
- **Hallucination Detection**: Compare bot responses against a knowledge base to catch incorrect information
- **Risk Classification**: Conversations are categorized as Safe, Warning, Critical, or Hallucination
- **Human Intervention**: Take over high-risk conversations with a single click
- **Simulated Conversations**: Generates realistic test conversations on startup

## Technology Stack

- **Framework**: Next.js 14 with App Router
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Icons**: Lucide React
- **State Management**: Zustand

## Getting Started

### Installation

```bash
npm install
```

### Development

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

### Build

```bash
npm run build
npm start
```

## Project Structure

```
src/
â”œâ”€â”€ app/                    # Next.js app router
â”‚   â”œâ”€â”€ layout.tsx         # Root layout with metadata
â”‚   â”œâ”€â”€ page.tsx           # Main page
â”‚   â””â”€â”€ globals.css        # Global styles
â”œâ”€â”€ components/            # React components
â”‚   â”œâ”€â”€ dashboard.tsx      # Main dashboard container
â”‚   â”œâ”€â”€ chat-list.tsx      # Left panel - chat list
â”‚   â”œâ”€â”€ chat-details.tsx   # Right panel - chat details
â”‚   â””â”€â”€ alert-badge.tsx    # Risk level indicators
â”œâ”€â”€ lib/                   # Core logic
â”‚   â”œâ”€â”€ types.ts           # TypeScript interfaces
â”‚   â”œâ”€â”€ supervisor-engine.ts  # Risk evaluation
â”‚   â””â”€â”€ simulation.ts      # Conversation generator
â”œâ”€â”€ store/                 # State management
â”‚   â””â”€â”€ chat-store.ts      # Zustand store
â””â”€â”€ data/                  # Static data
    â””â”€â”€ knowledgeBase.json # Ground truth policies
```

## How It Works

### Supervisor Engine

The supervisor engine evaluates each bot response using two critical rules:

1. **Sentiment Analysis**: Detects negative keywords indicating user frustration
2. **Grounding Check**: Compares responses against the knowledge base to detect hallucinations

### Risk Levels

- ðŸŸ¢ **Safe**: No issues detected
- ðŸŸ¡ **Warning**: Minor concerns
- ðŸ”´ **Critical**: User shows frustration
- ðŸŸ£ **Hallucination**: Bot provided incorrect information

### Intervention

When a conversation is flagged as Critical or Hallucination, a prominent "TAKE OVER CONVERSATION" button appears, allowing human supervisors to intervene immediately.

## License

MIT